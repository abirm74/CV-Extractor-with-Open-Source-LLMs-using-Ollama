{
  "name": "AMELIA MILLER",
  "phone": "+4-(294)-555-1234",
  "mail": "amefia@outiook.com",
  "location": "Los Angeles, CA",
  "linkedin": "",
  "education": [
    {
      "degree": "Master of Science in Computer Science",
      "university": "University of Southern California",
      "location": "Los Angeles, CA",
      "duration": "01/2012 - 01/2014"
    },
    {
      "degree": "Bachelor of Science in Information Technology",
      "university": "University of California, Berkeley",
      "location": "Berkeley, CA",
      "duration": "01/2008 - 01/2012"
    }
  ],
  "experience": [
    {
      "title": "Senior Big Data Engineer",
      "company": "DataTech Inc.",
      "duration": "09/2019 - Present",
      "location": "Los Angeles, CA",
      "full_description": "Led a team of 8 engineers to successfully migrate 70% of data workloads to Google Cloud Platform, resulting in a 20% reduction in operational costs.\n+ Implemented Ci/CD pipelines using GitHub and Jenkins, achieving a 40% reduction in deployment times and ensuring seamless integration of code changes.\n+ Developed a real-time data processing application using Kafka and Spark, improving data throughput by 25% and minimizing processing delays.\n\u00bb Established monitoring solutions with Grafana, decreasing response times to incidents by 20% through proactive alerting and dashboard insights.\n\u00ab Collaborated with cross-functional teams to integrate Hadoop-based solutions in the data architecture, enhancing data accessibility and compliance.\n\u00bb* Managed and scaled Kubermetes clusters, providing a resilient infrastructure that improved service uptime by 99.9% for client-facing applications."
    },
    {
      "title": "Big Data Developer",
      "company": "TechSolutions Carp.",
      "duration": "06/2016 - 08/2019",
      "location": "Santa Monica, CA",
      "full_description": "Designed and implemented scalable Hadoop workflows for data analytics, reducing data processing time by 50% across multiple departments.\n\u00bb Optimized MongoDB queries, improving data retrieval speeds by 40% and enhancing overall user experience with database-driven applications.\n\u00ab Conducted training sessions on Unix/Shell scripting for junior engineers, facilitating knowledge transfer and improving team competencies.\n\u00bb Spearheaded a project to automate routine data cleansing tasks using Python scripts, saving an estimated 200 hours of manual work monthly.\n\u00bb* Mapped data migration plans from legacy systems to Cloudera, ensuring data integrity and compliance during transition phases."
    },
    {
      "title": "Data Engineer",
      "company": "Innovate Analytics ig",
      "duration": "01/2014 - 05/2016",
      "location": "San Francisco, CA",
      "full_description": "Developed data pipelines using Apache Airflow, facilitating seamless data flow and effective reporting for business intelligence operations.\n\u00bb Implemented Ansible scripts for environment configuration, enhancing deployment processes and aligning team efforts toward agile methodologies.\n\u00bb Advised stakeholders on data strategy, resulting in improved decision-making processes and the implementation of innovative analytics solutions.\n\u00bb Reduced data processing costs by 15% through the optimization of existing systems and the implementation of scalable solutions."
    }
  ],
  "skills": [
    "UNIX",
    "Spark",
    "Shell Scripting",
    "Python",
    "Hadoop",
    "GitHub"
  ]
}