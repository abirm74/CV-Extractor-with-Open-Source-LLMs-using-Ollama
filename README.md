# ğŸš€ Resume Extractor

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat-square&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat-square&logo=fastapi&logoColor=white)
![React](https://img.shields.io/badge/React-61DAFB?style=flat-square&logo=react&logoColor=black)
![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)
![Status](https://img.shields.io/badge/Status-Active-brightgreen?style=flat-square)

**Transform PDF resumes into structured JSON data with AI-powered extraction** âœ¨

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [API](#-api-documentation) â€¢ [Contributing](#-contributing)

---

## ğŸ¯ Overview

Resume Extractor is an intelligent document processing system that converts PDF resumes (both text-based and scanned) into structured JSON format. Built with modern web technologies and powered by local LLM models via Ollama, it provides accurate data extraction with complete privacy.

### ğŸŒŸ Key Highlights

- ğŸ“„ **Dual PDF Support**: Handles both text-based and scanned/image-based resumes
- ğŸ¤– **AI-Powered**: Uses fine-tuned LLM models for intelligent data extraction
- ğŸ”’ **Privacy-First**: All processing happens locally - no data leaves your machine
- ğŸ“Š **Benchmarked**: Evaluated multiple models (Llama3, Mistral, Qwen) using precision, recall, and F1-score
- ğŸ¨ **Modern UI**: Beautiful, responsive React frontend with drag-and-drop functionality
- âš¡ **Fast API**: High-performance FastAPI backend with async processing

---

## âœ¨ Features

### ğŸ” **Smart Extraction**
- **Personal Information**: Name, phone, email, location, LinkedIn
- **Education**: Degrees, universities, locations, durations
- **Experience**: Job titles, companies, durations, locations, detailed descriptions
- **Skills**: Individual skill extraction and categorization

### ğŸ“‹ **Document Processing**
- **OCR Support**: Advanced text extraction from scanned PDFs using PyMuPDF
- **Text Parsing**: Direct text extraction from native PDF documents
- **Auto-Detection**: Automatically determines PDF type and applies appropriate processing
---

## ğŸ¬ Demo

### ğŸ“± **Web Interface**
- Drag & drop PDF upload
- Real-time PDF preview
- Instant JSON output
- Download extracted data
- Beautiful gradient UI with smooth animations

### ğŸ”„ **Processing Flow**
```mermaid
graph LR
    A[ğŸ“„ PDF Upload] --> B{ğŸ“‹ PDF Type?}
    B -->|Text-based| C[ğŸ“ Text Extraction]
    B -->|Scanned| D[ğŸ” OCR Processing]
    C --> E[ğŸ¤– LLM Processing]
    D --> E
    E --> F[ğŸ“Š JSON Output]
    F --> G[ğŸ’¾ Download/Display]
```

---

## ğŸ›  Installation

### Prerequisites
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull required model
ollama pull llama3:instruct
```

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/abirm74/CV-Extractor-with-Open-Source-LLMs-using-Ollama.git
cd resume-extractor
```

### 2ï¸âƒ£ Quick Setup (Recommended)
```bash
# Install all dependencies at once
npm run setup
```

### 3ï¸âƒ£ Manual Setup (Alternative)
```bash
# Backend dependencies
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Frontend dependencies
cd frontend && npm install
```

---

## ğŸš€ Usage

### ğŸ¯ **One-Command Start (Recommended)**
```bash
# Start both backend and frontend simultaneously
npm run dev
```
ğŸŒ API: `http://localhost:8000` | ğŸ¨ Web App: `http://localhost:3001`

### ğŸ”§ **Individual Commands**
```bash
# Backend only
npm run start-backend

# Frontend only  
npm run start-frontend

# Build frontend for production
npm run build
```

### ğŸ“± Using the Web Interface

1. **Upload**: Drag & drop or click to select PDF resume
2. **Preview**: View your PDF in the left panel
3. **Extract**: Click "Extract Resume Data" button
4. **Download**: Get structured JSON output

---

## ğŸ“š API Documentation

### ğŸ”Œ Endpoints

#### `POST /api/v1/upload`
Extract structured data from resume PDF

**Request:**
```bash
curl -X POST "http://localhost:8000/api/v1/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@resume.pdf"
```

**Response:**
```json
{
  "resume_data": {
    "name": "John Doe",
    "phone": "+1-234-567-8900",
    "mail": "john.doe@email.com",
    "location": "New York, NY",
    "linkedin": "linkedin.com/in/johndoe",
    "education": [...],
    "experience": [...],
    "skills": [...]
  },
  "extracted_text": "Raw extracted text..."
}
```

#### `GET /health`
API health check

#### `GET /docs`
Interactive API documentation (Swagger UI)

---

## ğŸ— Project Architecture

```
/project_root
â”‚
â”œâ”€â”€ package.json               # ğŸš€ Root scripts for easy development
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                      # Environment variables
â”‚
â”œâ”€â”€ ğŸ“ backend/               # FastAPI application
â”‚   â”œâ”€â”€ main.py              # Main FastAPI entry point
â”‚   â”œâ”€â”€ ğŸ“ api/              # API route handlers
â”‚   â”‚   â””â”€â”€ routes.py        # Upload & processing endpoints
â”‚   â””â”€â”€ ğŸ“ core/             # Core business logic
â”‚       â”œâ”€â”€ file_processor.py # OCR & text extraction
â”‚       â”œâ”€â”€ llm_processor.py  # LLM integration
â”‚       â””â”€â”€ resume_schema.py  # Pydantic models
â”‚
â”œâ”€â”€ ğŸ“ frontend/             # React application
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ ğŸ“ public/
â”‚   â””â”€â”€ ğŸ“ src/
â”‚       â”œâ”€â”€ App.js           # Main React component
â”‚       â”œâ”€â”€ index.js
â”‚       â””â”€â”€ index.css
â”‚
â”œâ”€â”€ ğŸ“ data/                 # Sample data
â”‚   â”œâ”€â”€ scanned_cvs/
â”‚   â””â”€â”€ text_cvs/
â”‚
â”œâ”€â”€ ğŸ“ evaluation/           # Model evaluation
â”‚   â”œâ”€â”€ ground_truth.json
â”‚   â””â”€â”€ evaluate.py
â”‚
â””â”€â”€ ğŸ“ outputs/             # Generated outputs
    â”œâ”€â”€ json_llama3_instruct/
    â”œâ”€â”€ json_mistral/
    â””â”€â”€ json_qwen_7b/
```

---

## ğŸ”® Upcoming Features

### ğŸ¯ **Job Matching Analysis**
- Compare resumes against job postings
- Calculate compatibility scores
- Provide improvement suggestions
- Highlight missing skills

### âš¡ **Performance Enhancements**
- Model quantization for faster inference
- Batch processing capabilities
- Caching mechanisms
- Async processing queues

### ğŸ¨ **UI/UX Improvements**
- Dark/light theme toggle
- Advanced filtering options
- Bulk processing interface
- Real-time processing status

---

## ğŸ”§ Technology Stack

### Backend
- **FastAPI**: Modern, fast web framework
- **PyMuPDF**: PDF processing and OCR
- **Ollama**: Local LLM inference
- **Pydantic**: Data validation and serialization

### Frontend
- **React 18**: Modern React with hooks
- **Lucide React**: Beautiful icons
- **React Dropzone**: File upload functionality
- **Axios**: HTTP client

### AI/ML
- **Llama3 Instruct**: Primary extraction model
- **Mistral & Qwen**: Alternative models for comparison
- **Custom Evaluation Pipeline**: Precision, recall, F1-score metrics

---

## ğŸ“Š Evaluation Metrics

Our evaluation pipeline tests extraction accuracy across multiple dimensions:

- **ğŸ¯ Precision**: Accuracy of extracted information
- **ğŸ“ˆ Recall**: Completeness of information extraction  
- **âš–ï¸ F1-Score**: Harmonic mean of precision and recall
- **ğŸ” Field-Level Analysis**: Individual field performance tracking

### ğŸ“‹ Test Dataset
- 100+ diverse resume samples
- Multiple formats and layouts
- Both text-based and scanned documents
- Ground truth annotations for validation

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### ğŸ› **Bug Reports**
Found a bug? Please open an issue with:
- Detailed description
- Steps to reproduce
- Expected vs actual behavior
- Sample files (if applicable)

### âœ¨ **Feature Requests**
Have an idea? We'd love to hear it! Open an issue with:
- Feature description
- Use case scenarios
- Potential implementation approach

### âš¡ **Available Scripts**

| Command | Description |
|---------|-------------|
| `npm run dev` | ğŸš€ Start both backend and frontend simultaneously |
| `npm run setup` | ğŸ“¦ Install all dependencies (backend + frontend) |
| `npm run start-backend` | ğŸ”§ Start only the FastAPI backend |
| `npm run start-frontend` | ğŸ¨ Start only the React frontend |
| `npm run build` | ğŸ“¦ Build frontend for production |
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Ollama Team** for the fantastic local LLM infrastructure
- **FastAPI** for the excellent web framework
- **React Community** for the amazing frontend ecosystem
- **PyMuPDF** for robust PDF processing capabilities

---

## ğŸ“ Support

- ğŸ“§ **Email**: moulaabir.am@gmail.com
- ğŸ’¬ **Issues**: [GitHub Issues](https://github.com/abirm74/CV-Extractor-with-Open-Source-LLMs-using-Ollama/issues)


---

### ğŸŒŸ If this project helped you, please give it a star! ğŸŒŸ

**Made with â¤ï¸ and lots of â˜•**

â­ [Star this repo](https://github.com/abirm74/CV-Extractor-with-Open-Source-LLMs-using-Ollama) â€¢ ğŸ´ [Fork it](https://github.com/abirm74/CV-Extractor-with-Open-Source-LLMs-using-Ollama/fork) â€¢ ğŸ› [Report issues](https://github.com/abirm74/CV-Extractor-with-Open-Source-LLMs-using-Ollama/issues)